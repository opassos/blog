{
  
    
        "post0": {
            "title": "Title",
            "content": ". Setup . !nvidia-smi . Sat Oct 16 21:51:52 2021 +--+ | NVIDIA-SMI 470.74 Driver Version: 460.32.03 CUDA Version: 11.2 | |-+-+-+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 A100-SXM4-40GB Off | 00000000:00:04.0 Off | 0 | | N/A 32C P0 43W / 400W | 0MiB / 40536MiB | 0% Default | | | | Disabled | +-+-+-+ +--+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | No running processes found | +--+ . !pip install -Uqqq fastai . |████████████████████████████████| 186 kB 5.1 MB/s |████████████████████████████████| 56 kB 4.8 MB/s . from fastai.vision.all import * . Dataset (MNIST) . path = untar_data(URLs.MNIST) . . 100.03% [15687680/15683414 00:00&lt;00:00] (path/&#39;testing&#39;).ls() . (#10) [Path(&#39;/root/.fastai/data/mnist_png/testing/3&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/9&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/2&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/5&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/7&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/6&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/8&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/1&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/4&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/0&#39;)] . (path/&#39;testing/6&#39;).ls() . (#958) [Path(&#39;/root/.fastai/data/mnist_png/testing/6/6933.png&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/6/3744.png&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/6/4239.png&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/6/3657.png&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/6/9138.png&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/6/366.png&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/6/8341.png&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/6/2728.png&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/6/3121.png&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing/6/2170.png&#39;)...] . um_seis = Image.open((path/&#39;testing/6&#39;).ls()[0]) um_seis . um_seis = tensor(um_seis) um_seis.shape . torch.Size([28, 28]) . um_seis[4:14, 4:14] . tensor([[ 0, 0, 0, 0, 0, 0, 0, 0, 70, 252], [ 0, 0, 0, 0, 0, 0, 0, 0, 112, 252], [ 0, 0, 0, 0, 0, 0, 0, 95, 246, 252], [ 0, 0, 0, 0, 0, 0, 3, 170, 253, 253], [ 0, 0, 0, 0, 0, 0, 118, 252, 252, 214], [ 0, 0, 0, 0, 0, 85, 253, 252, 233, 33], [ 0, 0, 0, 0, 0, 157, 253, 252, 89, 0], [ 0, 0, 0, 0, 0, 230, 253, 252, 69, 0], [ 0, 0, 0, 0, 51, 243, 255, 249, 63, 0], [ 0, 0, 0, 0, 93, 252, 253, 132, 0, 0]], dtype=torch.uint8) . 2**8 - 1 . 255 . EDA . (pd.DataFrame(um_seis) .style.set_properties( **{&#39;font-size&#39;:&#39;6pt&#39;, &#39;width&#39;: &#39;18px&#39;, &#39;text-align&#39;: &#39;center&#39;}) .background_gradient(&#39;Greys_r&#39;, vmax = 255, vmin = 0) ) . 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 . 0 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 104 | 253 | 181 | 9 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 13 | 215 | 252 | 249 | 75 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 70 | 252 | 252 | 199 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 112 | 252 | 252 | 116 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 6 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 95 | 246 | 252 | 252 | 11 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 7 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 3 | 170 | 253 | 253 | 128 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 8 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 118 | 252 | 252 | 214 | 18 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 9 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 85 | 253 | 252 | 233 | 33 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 10 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 157 | 253 | 252 | 89 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 11 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 230 | 253 | 252 | 69 | 0 | 0 | 0 | 0 | 0 | 95 | 63 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 12 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 51 | 243 | 255 | 249 | 63 | 0 | 0 | 0 | 36 | 222 | 253 | 253 | 181 | 9 | 0 | 0 | 0 | 0 | 0 | 0 | . 13 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 93 | 252 | 253 | 132 | 0 | 0 | 0 | 89 | 219 | 252 | 252 | 252 | 253 | 164 | 0 | 0 | 0 | 0 | 0 | 0 | . 14 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 93 | 252 | 253 | 92 | 0 | 0 | 32 | 222 | 252 | 252 | 195 | 246 | 253 | 240 | 50 | 0 | 0 | 0 | 0 | 0 | . 15 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 187 | 252 | 253 | 92 | 0 | 0 | 210 | 253 | 252 | 153 | 9 | 230 | 253 | 252 | 69 | 0 | 0 | 0 | 0 | 0 | . 16 0 | 0 | 0 | 0 | 0 | 0 | 0 | 64 | 248 | 252 | 232 | 8 | 0 | 189 | 250 | 253 | 106 | 38 | 210 | 250 | 253 | 157 | 6 | 0 | 0 | 0 | 0 | 0 | . 17 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 208 | 253 | 233 | 9 | 81 | 253 | 253 | 221 | 5 | 138 | 253 | 253 | 242 | 42 | 0 | 0 | 0 | 0 | 0 | 0 | . 18 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 169 | 227 | 253 | 173 | 197 | 252 | 252 | 193 | 136 | 252 | 252 | 252 | 178 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 19 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 32 | 253 | 252 | 252 | 252 | 252 | 253 | 252 | 252 | 252 | 221 | 63 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 20 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 56 | 219 | 252 | 252 | 252 | 253 | 252 | 252 | 218 | 88 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 21 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 15 | 54 | 137 | 242 | 253 | 178 | 137 | 35 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 22 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 23 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 24 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 25 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 26 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 27 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . um_seis = um_seis/255 . (pd.DataFrame(um_seis) .style.set_properties( **{&#39;font-size&#39;:&#39;6pt&#39;, &#39;width&#39;: &#39;18px&#39;, &#39;text-align&#39;: &#39;center&#39;}) .background_gradient(&#39;Greys_r&#39;, vmax = 1, vmin = 0) .format(&#39;{:.2f}&#39;) ) . 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 . 0 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 1 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 2 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.41 | 0.99 | 0.71 | 0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 3 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.05 | 0.84 | 0.99 | 0.98 | 0.29 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 4 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.27 | 0.99 | 0.99 | 0.78 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 5 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.44 | 0.99 | 0.99 | 0.45 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 6 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.37 | 0.96 | 0.99 | 0.99 | 0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 7 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.67 | 0.99 | 0.99 | 0.50 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 8 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.46 | 0.99 | 0.99 | 0.84 | 0.07 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 9 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.33 | 0.99 | 0.99 | 0.91 | 0.13 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 10 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.62 | 0.99 | 0.99 | 0.35 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 11 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.90 | 0.99 | 0.99 | 0.27 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.37 | 0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 12 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.20 | 0.95 | 1.00 | 0.98 | 0.25 | 0.00 | 0.00 | 0.00 | 0.14 | 0.87 | 0.99 | 0.99 | 0.71 | 0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 13 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.36 | 0.99 | 0.99 | 0.52 | 0.00 | 0.00 | 0.00 | 0.35 | 0.86 | 0.99 | 0.99 | 0.99 | 0.99 | 0.64 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 14 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.36 | 0.99 | 0.99 | 0.36 | 0.00 | 0.00 | 0.13 | 0.87 | 0.99 | 0.99 | 0.76 | 0.96 | 0.99 | 0.94 | 0.20 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 15 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.73 | 0.99 | 0.99 | 0.36 | 0.00 | 0.00 | 0.82 | 0.99 | 0.99 | 0.60 | 0.04 | 0.90 | 0.99 | 0.99 | 0.27 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 16 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.25 | 0.97 | 0.99 | 0.91 | 0.03 | 0.00 | 0.74 | 0.98 | 0.99 | 0.42 | 0.15 | 0.82 | 0.98 | 0.99 | 0.62 | 0.02 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 17 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.82 | 0.99 | 0.91 | 0.04 | 0.32 | 0.99 | 0.99 | 0.87 | 0.02 | 0.54 | 0.99 | 0.99 | 0.95 | 0.16 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 18 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.66 | 0.89 | 0.99 | 0.68 | 0.77 | 0.99 | 0.99 | 0.76 | 0.53 | 0.99 | 0.99 | 0.99 | 0.70 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 19 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.13 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.87 | 0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 20 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.22 | 0.86 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.85 | 0.35 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 21 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.06 | 0.21 | 0.54 | 0.95 | 0.99 | 0.70 | 0.54 | 0.14 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 22 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 23 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 24 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 25 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 26 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 27 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . Blur . kernel = torch.ones((3,3))/9 kernel . tensor([[0.1111, 0.1111, 0.1111], [0.1111, 0.1111, 0.1111], [0.1111, 0.1111, 0.1111]]) . um_seis.view(1,1,28,28).shape . torch.Size([1, 1, 28, 28]) . um_seis_borrado = F.conv2d(um_seis.view(1,1,28,28), kernel.view(1,1,3,3), padding=1) . (pd.DataFrame(um_seis_borrado.view(28,28)) .style.set_properties( **{&#39;font-size&#39;:&#39;6pt&#39;, &#39;width&#39;: &#39;18px&#39;, &#39;text-align&#39;: &#39;center&#39;}) .background_gradient(&#39;Greys_r&#39;, vmax = 1, vmin = 0) .format(&#39;{:.2f}&#39;) ) . 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 . 0 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 1 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.05 | 0.16 | 0.23 | 0.19 | 0.08 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 2 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.14 | 0.36 | 0.55 | 0.44 | 0.22 | 0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 3 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.04 | 0.28 | 0.61 | 0.85 | 0.64 | 0.31 | 0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 4 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.08 | 0.40 | 0.73 | 0.89 | 0.61 | 0.28 | 0.03 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 5 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.04 | 0.23 | 0.56 | 0.85 | 0.80 | 0.47 | 0.14 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 6 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.12 | 0.38 | 0.71 | 0.87 | 0.66 | 0.33 | 0.06 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 7 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.05 | 0.28 | 0.61 | 0.87 | 0.81 | 0.49 | 0.18 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 8 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.04 | 0.20 | 0.49 | 0.78 | 0.83 | 0.60 | 0.28 | 0.06 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 9 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.11 | 0.38 | 0.71 | 0.85 | 0.69 | 0.37 | 0.12 | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 10 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.21 | 0.54 | 0.87 | 0.83 | 0.51 | 0.18 | 0.01 | 0.00 | 0.00 | 0.04 | 0.07 | 0.07 | 0.03 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 11 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.02 | 0.30 | 0.63 | 0.93 | 0.76 | 0.42 | 0.10 | 0.00 | 0.02 | 0.11 | 0.26 | 0.39 | 0.37 | 0.22 | 0.08 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 12 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.06 | 0.38 | 0.71 | 0.92 | 0.66 | 0.33 | 0.06 | 0.04 | 0.15 | 0.36 | 0.58 | 0.72 | 0.70 | 0.51 | 0.26 | 0.08 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 13 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.10 | 0.43 | 0.76 | 0.86 | 0.57 | 0.23 | 0.04 | 0.15 | 0.37 | 0.67 | 0.84 | 0.95 | 0.93 | 0.81 | 0.50 | 0.20 | 0.02 | 0.00 | 0.00 | 0.00 | 0.00 | . 14 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.16 | 0.49 | 0.82 | 0.80 | 0.47 | 0.14 | 0.11 | 0.35 | 0.67 | 0.85 | 0.80 | 0.80 | 0.85 | 0.93 | 0.67 | 0.34 | 0.05 | 0.00 | 0.00 | 0.00 | 0.00 | . 15 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.03 | 0.26 | 0.59 | 0.88 | 0.73 | 0.41 | 0.17 | 0.30 | 0.61 | 0.80 | 0.78 | 0.64 | 0.69 | 0.83 | 0.93 | 0.67 | 0.34 | 0.05 | 0.00 | 0.00 | 0.00 | 0.00 | . 16 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.03 | 0.31 | 0.64 | 0.92 | 0.69 | 0.40 | 0.28 | 0.54 | 0.82 | 0.79 | 0.62 | 0.51 | 0.67 | 0.85 | 0.84 | 0.56 | 0.23 | 0.03 | 0.00 | 0.00 | 0.00 | 0.00 | . 17 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.03 | 0.30 | 0.62 | 0.90 | 0.71 | 0.52 | 0.51 | 0.75 | 0.92 | 0.73 | 0.58 | 0.61 | 0.83 | 0.93 | 0.71 | 0.38 | 0.09 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 18 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.16 | 0.39 | 0.71 | 0.73 | 0.74 | 0.75 | 0.89 | 0.95 | 0.79 | 0.74 | 0.78 | 0.93 | 0.86 | 0.55 | 0.23 | 0.02 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 19 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.07 | 0.19 | 0.43 | 0.64 | 0.83 | 0.92 | 0.96 | 0.96 | 0.91 | 0.91 | 0.92 | 0.89 | 0.66 | 0.35 | 0.11 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 20 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.15 | 0.36 | 0.59 | 0.73 | 0.85 | 0.94 | 0.95 | 0.91 | 0.80 | 0.63 | 0.38 | 0.16 | 0.03 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 21 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.02 | 0.13 | 0.26 | 0.40 | 0.52 | 0.61 | 0.62 | 0.58 | 0.47 | 0.32 | 0.15 | 0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 22 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.03 | 0.09 | 0.19 | 0.28 | 0.29 | 0.25 | 0.15 | 0.07 | 0.02 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 23 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 24 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 25 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 26 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 27 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . Muito borrada . kernel = torch.ones((7,7)) kernel = kernel/kernel.sum() kernel . tensor([[0.0204, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204], [0.0204, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204], [0.0204, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204], [0.0204, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204], [0.0204, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204], [0.0204, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204], [0.0204, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204, 0.0204]]) . Dica: para manter a imagem do mesmo tamanho, padding vale k//2 . um_seis_muito_borrado = F.conv2d( um_seis.view(1,1,28,28), kernel.view(1,1,7,7), padding=3) . (pd.DataFrame(um_seis_muito_borrado.view(28,28)) .style.set_properties( **{&#39;font-size&#39;:&#39;6pt&#39;, &#39;width&#39;: &#39;18px&#39;, &#39;text-align&#39;: &#39;center&#39;}) .background_gradient(&#39;Greys_r&#39;, vmax = 1, vmin = 0) .format(&#39;{:.2f}&#39;) ) . 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 . 0 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.03 | 0.07 | 0.10 | 0.11 | 0.11 | 0.11 | 0.11 | 0.08 | 0.04 | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 1 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.05 | 0.11 | 0.16 | 0.17 | 0.17 | 0.17 | 0.16 | 0.12 | 0.06 | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 2 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.02 | 0.08 | 0.16 | 0.22 | 0.23 | 0.23 | 0.23 | 0.21 | 0.15 | 0.07 | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 3 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.04 | 0.13 | 0.23 | 0.29 | 0.30 | 0.30 | 0.29 | 0.25 | 0.17 | 0.07 | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 4 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.02 | 0.08 | 0.18 | 0.29 | 0.35 | 0.36 | 0.36 | 0.34 | 0.28 | 0.18 | 0.07 | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 5 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.05 | 0.13 | 0.25 | 0.36 | 0.42 | 0.43 | 0.42 | 0.38 | 0.30 | 0.18 | 0.07 | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 6 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.04 | 0.10 | 0.19 | 0.31 | 0.40 | 0.45 | 0.45 | 0.42 | 0.36 | 0.26 | 0.14 | 0.05 | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 7 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.02 | 0.07 | 0.15 | 0.25 | 0.35 | 0.42 | 0.45 | 0.43 | 0.38 | 0.30 | 0.20 | 0.10 | 0.03 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 8 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.04 | 0.11 | 0.21 | 0.31 | 0.39 | 0.44 | 0.45 | 0.42 | 0.34 | 0.25 | 0.16 | 0.07 | 0.02 | 0.01 | 0.01 | 0.01 | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 9 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.06 | 0.15 | 0.27 | 0.37 | 0.43 | 0.46 | 0.46 | 0.40 | 0.33 | 0.24 | 0.17 | 0.12 | 0.09 | 0.09 | 0.09 | 0.07 | 0.04 | 0.02 | 0.00 | 0.00 | 0.00 | 0.00 | . 10 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.09 | 0.20 | 0.32 | 0.40 | 0.44 | 0.45 | 0.45 | 0.39 | 0.32 | 0.24 | 0.21 | 0.21 | 0.21 | 0.20 | 0.18 | 0.14 | 0.09 | 0.05 | 0.01 | 0.00 | 0.00 | 0.00 | . 11 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.02 | 0.12 | 0.25 | 0.37 | 0.42 | 0.44 | 0.45 | 0.45 | 0.40 | 0.32 | 0.27 | 0.28 | 0.31 | 0.34 | 0.32 | 0.28 | 0.22 | 0.16 | 0.09 | 0.04 | 0.00 | 0.00 | 0.00 | . 12 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.03 | 0.15 | 0.29 | 0.40 | 0.44 | 0.44 | 0.46 | 0.47 | 0.41 | 0.34 | 0.30 | 0.35 | 0.42 | 0.45 | 0.42 | 0.36 | 0.29 | 0.22 | 0.14 | 0.06 | 0.01 | 0.00 | 0.00 | . 13 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.06 | 0.19 | 0.33 | 0.42 | 0.43 | 0.45 | 0.48 | 0.50 | 0.43 | 0.37 | 0.36 | 0.45 | 0.53 | 0.55 | 0.50 | 0.43 | 0.36 | 0.27 | 0.17 | 0.08 | 0.01 | 0.00 | 0.00 | . 14 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.08 | 0.21 | 0.35 | 0.42 | 0.44 | 0.47 | 0.53 | 0.54 | 0.47 | 0.42 | 0.45 | 0.56 | 0.64 | 0.65 | 0.57 | 0.50 | 0.42 | 0.32 | 0.19 | 0.08 | 0.01 | 0.00 | 0.00 | . 15 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.09 | 0.23 | 0.37 | 0.43 | 0.45 | 0.51 | 0.58 | 0.60 | 0.54 | 0.51 | 0.56 | 0.67 | 0.75 | 0.73 | 0.65 | 0.57 | 0.46 | 0.35 | 0.21 | 0.08 | 0.01 | 0.00 | 0.00 | . 16 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.08 | 0.21 | 0.35 | 0.41 | 0.45 | 0.52 | 0.62 | 0.66 | 0.63 | 0.60 | 0.66 | 0.75 | 0.79 | 0.76 | 0.65 | 0.56 | 0.45 | 0.33 | 0.20 | 0.08 | 0.01 | 0.00 | 0.00 | . 17 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.08 | 0.18 | 0.30 | 0.37 | 0.43 | 0.53 | 0.64 | 0.70 | 0.70 | 0.69 | 0.73 | 0.79 | 0.79 | 0.73 | 0.61 | 0.51 | 0.40 | 0.29 | 0.16 | 0.07 | 0.01 | 0.00 | 0.00 | . 18 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.07 | 0.15 | 0.25 | 0.32 | 0.38 | 0.49 | 0.62 | 0.69 | 0.70 | 0.70 | 0.74 | 0.77 | 0.74 | 0.64 | 0.52 | 0.42 | 0.32 | 0.22 | 0.12 | 0.04 | 0.01 | 0.00 | 0.00 | . 19 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.06 | 0.12 | 0.20 | 0.25 | 0.32 | 0.43 | 0.54 | 0.61 | 0.62 | 0.62 | 0.67 | 0.68 | 0.64 | 0.53 | 0.42 | 0.34 | 0.26 | 0.16 | 0.08 | 0.02 | 0.00 | 0.00 | 0.00 | . 20 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.03 | 0.07 | 0.13 | 0.19 | 0.26 | 0.35 | 0.45 | 0.51 | 0.54 | 0.55 | 0.58 | 0.58 | 0.53 | 0.43 | 0.34 | 0.27 | 0.19 | 0.11 | 0.04 | 0.00 | 0.00 | 0.00 | 0.00 | . 21 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.03 | 0.08 | 0.13 | 0.19 | 0.26 | 0.34 | 0.41 | 0.45 | 0.48 | 0.49 | 0.47 | 0.42 | 0.34 | 0.26 | 0.20 | 0.12 | 0.06 | 0.02 | 0.00 | 0.00 | 0.00 | 0.00 | . 22 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.03 | 0.07 | 0.11 | 0.16 | 0.22 | 0.28 | 0.33 | 0.36 | 0.36 | 0.34 | 0.30 | 0.24 | 0.18 | 0.12 | 0.07 | 0.03 | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | . 23 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.02 | 0.05 | 0.08 | 0.12 | 0.16 | 0.19 | 0.22 | 0.22 | 0.20 | 0.17 | 0.13 | 0.09 | 0.06 | 0.03 | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 24 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.02 | 0.04 | 0.06 | 0.07 | 0.08 | 0.08 | 0.08 | 0.07 | 0.05 | 0.03 | 0.01 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 25 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 26 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 27 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . &#39;desborrado&#39; . kernel = torch.tensor( [[ 0, -1, 0], [-1, 5, -1], [ 0, -1, 0]], dtype = torch.float ) um_seis_desborrado = F.conv2d(um_seis.view(1,1,28,28), kernel.view(1,1,3,3), padding=1) (pd.DataFrame(um_seis_desborrado.view(28,28)) .style.set_properties( **{&#39;font-size&#39;:&#39;6pt&#39;, &#39;width&#39;: &#39;18px&#39;, &#39;text-align&#39;: &#39;center&#39;}) .background_gradient(&#39;Greys_r&#39;, vmax = 1, vmin = 0) .format(&#39;{:.2f}&#39;) ) . 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 . 0 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 1 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.41 | -0.99 | -0.71 | -0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 2 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.46 | 0.20 | 2.85 | 1.55 | -0.83 | -0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 3 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.05 | -0.86 | 1.78 | 1.14 | 2.11 | 0.46 | -0.29 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 4 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.27 | -0.11 | 1.85 | 1.20 | 1.48 | -1.07 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 5 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.81 | -0.03 | 1.54 | 1.52 | 0.46 | -0.45 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 6 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.38 | 0.23 | 2.03 | 1.01 | 2.42 | -1.23 | -0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 7 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.01 | -1.07 | 0.97 | 1.35 | 1.64 | 0.46 | -0.55 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 8 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.80 | 0.32 | 1.84 | 1.21 | 2.02 | -0.99 | -0.07 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 9 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.33 | 0.06 | 2.18 | 1.06 | 2.11 | -1.11 | -0.20 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 10 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.62 | 0.85 | 1.37 | 1.62 | -0.43 | -0.48 | 0.00 | 0.00 | 0.00 | 0.00 | -0.37 | -0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 11 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -1.10 | 1.95 | 1.08 | 1.71 | -0.23 | -0.27 | 0.00 | 0.00 | -0.14 | -1.24 | 0.62 | -0.13 | -0.96 | -0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 12 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.20 | -0.32 | 1.67 | 1.09 | 2.13 | -0.01 | -0.25 | 0.00 | -0.49 | -1.02 | 2.23 | 1.74 | 2.02 | 1.53 | -1.18 | -0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 13 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.36 | 0.27 | 1.64 | 1.46 | 0.26 | -0.76 | 0.00 | -0.47 | 0.02 | 1.83 | 1.24 | 1.21 | 1.00 | 1.63 | 1.25 | -0.84 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 14 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.36 | -0.26 | 1.61 | 1.63 | -0.07 | -0.36 | -0.13 | -1.07 | 1.90 | 1.24 | 1.60 | 0.85 | 1.18 | 1.07 | 1.89 | -0.23 | -0.20 | 0.00 | 0.00 | 0.00 | 0.00 | . 15 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.98 | 1.34 | 1.24 | 1.71 | 0.42 | -0.36 | -1.56 | 2.02 | 1.29 | 1.95 | 0.84 | -2.91 | 1.54 | 1.09 | 2.12 | 0.15 | -0.27 | 0.00 | 0.00 | 0.00 | 0.00 | . 16 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.25 | 0.28 | 2.07 | 1.08 | 1.62 | -1.15 | -1.09 | 1.73 | 1.35 | 1.71 | -0.07 | -1.64 | 1.96 | 1.19 | 1.42 | 0.91 | -0.77 | -0.02 | 0.00 | 0.00 | 0.00 | 0.00 | . 17 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -1.07 | 1.45 | 1.35 | 1.64 | -1.76 | -0.21 | 1.92 | 1.13 | 1.57 | -2.26 | 0.56 | 1.62 | 1.05 | 1.90 | -0.74 | -0.19 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 18 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.66 | 1.61 | 1.68 | 1.49 | 0.60 | 0.89 | 1.20 | 1.22 | 0.40 | -0.09 | 1.89 | 0.98 | 1.40 | 1.31 | -0.86 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 19 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.79 | -1.25 | 2.64 | 1.42 | 1.20 | 0.99 | 0.98 | 1.24 | 1.44 | 0.99 | 1.24 | 1.76 | -0.33 | -0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 20 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.35 | -0.75 | 2.04 | 1.89 | 1.44 | 1.02 | 1.00 | 1.27 | 1.57 | 1.82 | 0.00 | -0.59 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 21 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.28 | -0.78 | -0.53 | 0.54 | 2.23 | 2.32 | 0.97 | 0.86 | -0.71 | -0.48 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 22 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.06 | -0.21 | -0.54 | -0.95 | -0.99 | -0.70 | -0.54 | -0.14 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 23 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 24 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 25 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 26 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 27 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . Borda . kernel = torch.tensor( [[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], dtype = torch.float ) um_seis_bordado = F.conv2d(um_seis.view(1,1,28,28), kernel.view(1,1,3,3), padding=1) (pd.DataFrame(um_seis_bordado.view(28,28)) .style.set_properties( **{&#39;font-size&#39;:&#39;6pt&#39;, &#39;width&#39;: &#39;18px&#39;, &#39;text-align&#39;: &#39;center&#39;}) .background_gradient(&#39;Greys_r&#39;, vmax = 1, vmin = 0) .format(&#39;{:.2f}&#39;) ) . 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 . 0 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 1 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.41 | -1.40 | -2.11 | -1.74 | -0.75 | -0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 2 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.05 | -1.30 | 0.39 | 4.01 | 2.39 | -1.70 | -0.33 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 3 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.33 | -2.11 | 2.05 | 1.22 | 3.02 | -0.15 | -0.33 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 4 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.76 | -1.11 | 2.35 | 0.90 | 1.55 | -2.51 | -0.29 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 5 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.37 | -2.05 | -1.06 | 1.29 | 1.69 | -0.15 | -1.28 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 6 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.01 | -1.05 | -0.09 | 2.28 | 1.05 | 2.95 | -2.59 | -0.50 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 7 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.47 | -2.40 | 0.55 | 1.14 | 1.60 | 0.09 | -1.60 | -0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 8 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.33 | -1.80 | -0.28 | 1.89 | 1.40 | 2.13 | -1.90 | -0.57 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 9 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.95 | -0.40 | 2.57 | 1.23 | 2.04 | -2.13 | -1.04 | -0.07 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 10 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -1.85 | 0.71 | 1.14 | 1.42 | -1.49 | -1.66 | -0.13 | 0.00 | 0.00 | -0.37 | -0.62 | -0.62 | -0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 11 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.20 | -2.67 | 2.46 | 0.52 | 2.09 | -1.38 | -0.87 | 0.00 | -0.14 | -1.01 | -2.38 | -0.12 | -1.09 | -1.98 | -0.75 | -0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 12 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.56 | -1.61 | 2.18 | 0.69 | 2.80 | -0.78 | -0.52 | -0.35 | -1.35 | -1.94 | 2.62 | 2.49 | 2.65 | 1.78 | -2.06 | -0.68 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 13 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.93 | -0.58 | 2.05 | 1.16 | -0.43 | -2.10 | -0.37 | -1.35 | -0.19 | 1.67 | 1.31 | 0.36 | 0.51 | 1.67 | 1.28 | -1.82 | -0.20 | 0.00 | 0.00 | 0.00 | 0.00 | . 14 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -1.46 | -1.15 | 1.49 | 1.75 | -0.97 | -1.24 | -0.95 | -2.03 | 1.84 | 1.27 | 1.69 | -0.34 | 1.06 | 0.53 | 2.45 | -1.27 | -0.47 | 0.00 | 0.00 | 0.00 | 0.00 | . 15 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.25 | -2.32 | 1.31 | 0.96 | 2.32 | -0.40 | -1.49 | -2.67 | 1.89 | 1.75 | 1.91 | -0.35 | -5.89 | 0.67 | 0.56 | 2.88 | -0.60 | -0.49 | 0.00 | 0.00 | 0.00 | 0.00 | . 16 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.25 | -0.51 | 3.01 | 0.59 | 1.98 | -3.28 | -2.48 | 1.82 | 1.44 | 1.86 | -1.82 | -3.22 | 1.40 | 1.16 | 1.35 | 0.55 | -1.85 | -0.29 | 0.00 | 0.00 | 0.00 | 0.00 | . 17 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.25 | -2.70 | 1.77 | 0.79 | 1.79 | -4.33 | -1.70 | 2.16 | 0.63 | 1.25 | -5.09 | -0.58 | 1.49 | 0.53 | 2.16 | -1.96 | -0.80 | -0.02 | 0.00 | 0.00 | 0.00 | 0.00 | . 18 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -1.48 | 2.48 | 1.63 | 2.32 | -0.57 | 0.20 | 0.88 | 0.34 | -0.31 | -1.87 | 1.87 | 0.56 | 1.18 | 1.38 | -2.06 | -0.16 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 19 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.66 | -1.68 | -2.75 | 3.18 | 1.42 | 0.65 | 0.22 | 0.22 | 0.71 | 0.68 | 0.59 | 0.90 | 1.82 | -0.92 | -0.95 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 20 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.13 | -1.34 | -1.27 | 2.42 | 2.29 | 1.27 | 0.48 | 0.35 | 0.73 | 1.73 | 1.99 | -0.33 | -1.46 | -0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 21 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.22 | -1.14 | -1.81 | -1.74 | 0.17 | 3.09 | 3.32 | 1.09 | 0.63 | -1.63 | -1.34 | -0.35 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 22 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.06 | -0.27 | -0.81 | -1.70 | -2.48 | -2.64 | -2.23 | -1.37 | -0.67 | -0.14 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 23 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 24 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 25 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 26 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 27 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . (pd.DataFrame(um_seis.view(28,28)) .style.set_properties( **{&#39;font-size&#39;:&#39;6pt&#39;, &#39;width&#39;: &#39;18px&#39;, &#39;text-align&#39;: &#39;center&#39;}) .background_gradient(&#39;Greys_r&#39;, vmax = 1, vmin = 0) .format(&#39;{:.2f}&#39;) ) . 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 . 0 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 1 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 2 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.41 | 0.99 | 0.71 | 0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 3 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.05 | 0.84 | 0.99 | 0.98 | 0.29 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 4 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.27 | 0.99 | 0.99 | 0.78 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 5 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.44 | 0.99 | 0.99 | 0.45 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 6 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.37 | 0.96 | 0.99 | 0.99 | 0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 7 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.67 | 0.99 | 0.99 | 0.50 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 8 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.46 | 0.99 | 0.99 | 0.84 | 0.07 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 9 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.33 | 0.99 | 0.99 | 0.91 | 0.13 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 10 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.62 | 0.99 | 0.99 | 0.35 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 11 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.90 | 0.99 | 0.99 | 0.27 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.37 | 0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 12 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.20 | 0.95 | 1.00 | 0.98 | 0.25 | 0.00 | 0.00 | 0.00 | 0.14 | 0.87 | 0.99 | 0.99 | 0.71 | 0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 13 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.36 | 0.99 | 0.99 | 0.52 | 0.00 | 0.00 | 0.00 | 0.35 | 0.86 | 0.99 | 0.99 | 0.99 | 0.99 | 0.64 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 14 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.36 | 0.99 | 0.99 | 0.36 | 0.00 | 0.00 | 0.13 | 0.87 | 0.99 | 0.99 | 0.76 | 0.96 | 0.99 | 0.94 | 0.20 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 15 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.73 | 0.99 | 0.99 | 0.36 | 0.00 | 0.00 | 0.82 | 0.99 | 0.99 | 0.60 | 0.04 | 0.90 | 0.99 | 0.99 | 0.27 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 16 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.25 | 0.97 | 0.99 | 0.91 | 0.03 | 0.00 | 0.74 | 0.98 | 0.99 | 0.42 | 0.15 | 0.82 | 0.98 | 0.99 | 0.62 | 0.02 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 17 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.82 | 0.99 | 0.91 | 0.04 | 0.32 | 0.99 | 0.99 | 0.87 | 0.02 | 0.54 | 0.99 | 0.99 | 0.95 | 0.16 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 18 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.66 | 0.89 | 0.99 | 0.68 | 0.77 | 0.99 | 0.99 | 0.76 | 0.53 | 0.99 | 0.99 | 0.99 | 0.70 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 19 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.13 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.87 | 0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 20 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.22 | 0.86 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.85 | 0.35 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 21 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.06 | 0.21 | 0.54 | 0.95 | 0.99 | 0.70 | 0.54 | 0.14 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 22 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 23 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 24 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 25 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 26 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 27 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . ( 0.99*-1 + 0.99*-1 + 0.99*-1 + 0.94*0 + 0.99*0 + 0.62*0 + 0.2*1 + 0.27*1 + 0.02*1 ) . -2.4799999999999995 . ( 0*-1 + 0.25*-1 + 0*-1 + 0.73*0 + 0.97*0 + 0.82*0 + 0.99*1 + 0.99*1 + 0.99*1 ) . 2.7199999999999998 . kernel = torch.tensor( [[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], dtype = torch.float ) um_seis_bordado = F.conv2d(um_seis.view(1,1,28,28), kernel.view(1,1,3,3), padding=1) (pd.DataFrame(um_seis_bordado.view(28,28)) .style.set_properties( **{&#39;font-size&#39;:&#39;6pt&#39;, &#39;width&#39;: &#39;18px&#39;, &#39;text-align&#39;: &#39;center&#39;}) .background_gradient(&#39;Greys_r&#39;, vmax = 1, vmin = -1) .format(&#39;{:.2f}&#39;) ) . 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 . 0 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 1 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.41 | 0.99 | 0.30 | -0.96 | -0.71 | -0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 2 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.05 | 1.25 | 1.93 | 0.44 | -1.65 | -1.69 | -0.33 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 3 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.33 | 2.24 | 2.64 | 0.23 | -2.64 | -2.47 | -0.33 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 4 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.76 | 2.82 | 2.20 | -0.61 | -2.67 | -2.21 | -0.29 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 5 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.37 | 1.68 | 2.59 | 1.29 | -1.69 | -2.96 | -1.28 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 6 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 1.04 | 2.38 | 1.93 | 0.08 | -2.47 | -2.48 | -0.50 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 7 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.47 | 2.03 | 2.47 | 0.79 | -1.38 | -2.78 | -1.56 | -0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 8 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.33 | 1.47 | 2.31 | 1.43 | -0.68 | -2.32 | -1.96 | -0.57 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 9 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.95 | 2.45 | 2.02 | -0.20 | -2.00 | -2.18 | -0.97 | -0.07 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 10 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 1.85 | 2.98 | 1.11 | -1.44 | -2.84 | -1.53 | -0.13 | 0.00 | 0.00 | 0.37 | 0.25 | -0.37 | -0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 11 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.20 | 2.47 | 2.78 | 0.48 | -2.12 | -2.95 | -0.87 | 0.00 | 0.14 | 0.87 | 1.22 | 0.37 | -0.65 | -1.20 | -0.71 | -0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 12 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.56 | 2.84 | 2.42 | -0.36 | -2.47 | -2.48 | -0.52 | 0.35 | 1.00 | 1.51 | 1.35 | 0.37 | -0.65 | -1.55 | -1.70 | -0.68 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 13 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.93 | 2.93 | 2.05 | -1.07 | -2.74 | -1.85 | -0.12 | 1.22 | 1.86 | 1.63 | 0.76 | 0.10 | -0.05 | -1.33 | -2.50 | -1.62 | -0.20 | 0.00 | 0.00 | 0.00 | 0.00 | . 14 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 1.46 | 2.96 | 1.51 | -1.73 | -2.98 | -1.24 | 0.95 | 2.21 | 1.89 | 0.36 | -1.05 | 0.28 | 1.19 | -0.28 | -2.51 | -2.57 | -0.47 | 0.00 | 0.00 | 0.00 | 0.00 | . 15 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.25 | 2.07 | 2.71 | 0.82 | -2.21 | -2.89 | -0.01 | 1.93 | 2.11 | 0.46 | -1.12 | -0.77 | 1.11 | 1.35 | -0.30 | -2.49 | -2.55 | -0.49 | 0.00 | 0.00 | 0.00 | 0.00 | . 16 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.25 | 2.52 | 2.72 | 0.29 | -2.54 | -2.50 | 1.31 | 2.48 | 1.12 | -1.37 | -1.56 | 0.43 | 1.58 | 1.08 | -1.11 | -2.64 | -1.77 | -0.29 | 0.00 | 0.00 | 0.00 | 0.00 | . 17 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.25 | 2.45 | 2.62 | 0.36 | -2.13 | -1.73 | 1.98 | 1.87 | -0.11 | -1.99 | -0.94 | 1.84 | 1.28 | -0.16 | -2.18 | -2.62 | -0.78 | -0.02 | 0.00 | 0.00 | 0.00 | 0.00 | . 18 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 1.48 | 2.01 | 1.42 | -0.31 | -0.82 | 1.27 | 0.89 | -0.35 | -1.43 | -0.10 | 1.43 | 0.33 | -1.07 | -2.68 | -1.89 | -0.16 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 19 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.66 | 1.02 | 1.54 | 1.51 | 0.55 | 0.44 | 0.22 | -0.22 | -0.45 | 0.22 | 0.32 | -0.76 | -1.89 | -2.20 | -0.95 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 20 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.13 | 1.21 | 1.78 | 0.98 | 0.61 | 0.74 | 0.46 | -0.25 | -0.46 | -0.69 | -1.30 | -1.73 | -1.21 | -0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 21 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.22 | 0.92 | 0.98 | 0.61 | 0.74 | 0.46 | -0.25 | -0.46 | -0.69 | -1.18 | -0.99 | -0.35 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 22 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.06 | 0.21 | 0.48 | 0.74 | 0.45 | -0.25 | -0.45 | -0.56 | -0.54 | -0.14 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 23 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 24 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 25 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 26 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 27 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . kernel = torch.tensor( [[-1, -1, -1], [ 0, 0, 0], [ 1, 1, 1]], dtype = torch.float ) um_seis_bordado = F.conv2d(um_seis.view(1,1,28,28), kernel.view(1,1,3,3), padding=1) (pd.DataFrame(um_seis_bordado.view(28,28)) .style.set_properties( **{&#39;font-size&#39;:&#39;6pt&#39;, &#39;width&#39;: &#39;18px&#39;, &#39;text-align&#39;: &#39;center&#39;}) .background_gradient(&#39;Greys_r&#39;, vmax = 1, vmin = -1) .format(&#39;{:.2f}&#39;) ) . 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 . 0 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 1 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.41 | 1.40 | 2.11 | 1.74 | 0.75 | 0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 2 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.05 | 0.89 | 1.88 | 2.81 | 2.26 | 1.27 | 0.29 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 3 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.27 | 0.85 | 0.85 | 0.65 | 0.03 | 0.04 | -0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 4 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.39 | 0.53 | 0.53 | -0.38 | -0.82 | -0.82 | -0.29 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 5 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.37 | 1.06 | 1.06 | 0.69 | -0.74 | -0.74 | -0.74 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 6 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.01 | 0.68 | 1.23 | 1.22 | 0.07 | -0.94 | -0.94 | -0.45 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 7 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.46 | 1.08 | 1.10 | 0.49 | -1.04 | -1.11 | -0.96 | -0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 8 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.33 | 1.31 | 1.64 | 1.22 | -0.62 | -1.44 | -1.36 | -0.50 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 9 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.62 | 1.15 | 1.15 | -0.11 | -1.48 | -1.55 | -0.91 | -0.07 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 10 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.57 | 0.57 | 0.57 | -0.64 | -0.77 | -0.77 | -0.13 | 0.00 | 0.00 | 0.37 | 0.62 | 0.62 | 0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 11 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.20 | 0.54 | 0.55 | 0.33 | -0.11 | -0.11 | -0.10 | 0.00 | 0.14 | 1.01 | 2.00 | 2.85 | 2.69 | 1.74 | 0.75 | 0.04 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 12 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.36 | 0.45 | 0.45 | -0.38 | -0.74 | -0.74 | -0.27 | 0.35 | 1.21 | 2.20 | 2.46 | 2.35 | 2.35 | 2.38 | 1.64 | 0.64 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 13 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.16 | 0.20 | 0.19 | -0.59 | -0.87 | -0.86 | -0.12 | 1.00 | 1.84 | 1.84 | 0.74 | -0.14 | 0.03 | 1.16 | 1.38 | 1.10 | 0.20 | 0.00 | 0.00 | 0.00 | 0.00 | . 14 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.37 | 0.37 | 0.37 | -0.16 | -0.16 | -0.16 | 0.82 | 1.47 | 1.60 | 0.38 | -1.21 | -1.43 | -1.04 | 0.26 | 0.62 | 0.62 | 0.27 | 0.00 | 0.00 | 0.00 | 0.00 | . 15 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.25 | 0.86 | 0.86 | 0.53 | -0.41 | -0.41 | 0.41 | 1.60 | 1.72 | 0.40 | -1.29 | -1.35 | -0.76 | 0.07 | -0.31 | -0.50 | -0.50 | -0.17 | 0.00 | 0.00 | 0.00 | 0.00 | . 16 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.08 | 0.09 | 0.01 | -0.40 | -0.09 | 0.98 | 1.48 | 1.04 | -0.93 | -1.15 | -0.07 | 0.99 | 1.00 | -0.78 | -1.14 | -1.09 | -0.27 | 0.00 | 0.00 | 0.00 | 0.00 | . 17 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.25 | -0.56 | -0.66 | -0.33 | 0.63 | 1.50 | 1.67 | 1.03 | 0.02 | -0.11 | 0.72 | 1.12 | 1.01 | -0.12 | -0.90 | -0.93 | -0.64 | -0.02 | 0.00 | 0.00 | 0.00 | 0.00 | . 18 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.82 | -1.68 | -1.60 | 0.16 | 1.70 | 1.62 | 0.66 | 0.12 | 1.09 | 1.54 | 1.41 | 0.32 | -0.83 | -0.99 | -0.87 | -0.16 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 19 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.66 | -1.55 | -2.33 | -1.48 | -0.38 | 0.40 | 0.22 | 0.24 | 0.69 | 0.69 | 0.32 | -0.78 | -1.47 | -1.34 | -0.70 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 20 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.13 | -1.12 | -2.05 | -2.70 | -2.16 | -1.27 | -0.49 | -0.33 | -0.74 | -1.59 | -2.17 | -1.96 | -1.11 | -0.25 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 21 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.22 | -1.08 | -2.07 | -2.84 | -2.96 | -2.97 | -2.97 | -2.97 | -2.83 | -2.19 | -1.20 | -0.35 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 22 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | -0.06 | -0.27 | -0.81 | -1.70 | -2.48 | -2.64 | -2.23 | -1.37 | -0.67 | -0.14 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 23 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 24 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 25 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 26 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . 27 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | . kernel = torch.tensor( [[-1, -1, -1], [ 0, 0, 0], [ 1, 1, 1]], dtype = torch.float ) plt.imshow(kernel, cmap = &#39;bwr&#39;); . CNN . Path: /root/.fastai/data/mnist_png . tarining . 0 | 1 | 2 | ... | . | testing . 0 | 1 | 2 | ... | . | . path.ls() . (#2) [Path(&#39;/root/.fastai/data/mnist_png/training&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing&#39;)] . dls = DataBlock( blocks = (ImageBlock(cls=PILImageBW), CategoryBlock), get_items = get_image_files, splitter = GrandparentSplitter(train_name=&#39;training&#39;, valid_name=&#39;testing&#39;), get_y = parent_label ).dataloaders(path, bs = 128, num_workers = 10) dls.show_batch() . learn = Learner(dls, xresnet18(c_in = 1), metrics = error_rate) . learn.fit_one_cycle(5) . epoch train_loss valid_loss error_rate time . 0 | 0.095464 | 0.093186 | 0.029300 | 00:17 | . 1 | 0.056486 | 0.045684 | 0.015800 | 00:17 | . 2 | 0.028911 | 0.031794 | 0.010800 | 00:16 | . 3 | 0.010618 | 0.018615 | 0.006500 | 00:17 | . 4 | 0.004242 | 0.018373 | 0.005600 | 00:17 | . /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /pytorch/c10/core/TensorImpl.h:1156.) return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode) . model = learn.model . kernels = model[0][0].weight.cpu().detach().numpy() kernels . kernels.shape . (32, 1, 3, 3) . cols = 8 rows = 4 fig = plt.figure(figsize=(cols, 1.2*rows)) for i in range(rows*cols): img = kernels[i, 0] fig.add_subplot(rows, cols, i + 1) plt.imshow(img, cmap=&#39;bwr&#39;) plt.title(f&#39;K{i+1}&#39;) plt.axis(&#39;off&#39;) plt.show() . learn.summary() . XResNet (Input shape: 128) ============================================================================ Layer (type) Output Shape Param # Trainable ============================================================================ 128 x 32 x 14 x 14 Conv2d 288 True BatchNorm2d 64 True ReLU Conv2d 9216 True BatchNorm2d 64 True ReLU ____________________________________________________________________________ 128 x 64 x 14 x 14 Conv2d 18432 True BatchNorm2d 128 True ReLU MaxPool2d Conv2d 36864 True BatchNorm2d 128 True ReLU Conv2d 36864 True BatchNorm2d 128 True Sequential ReLU Conv2d 36864 True BatchNorm2d 128 True ReLU Conv2d 36864 True BatchNorm2d 128 True Sequential ReLU ____________________________________________________________________________ 128 x 128 x 4 x 4 Conv2d 73728 True BatchNorm2d 256 True ReLU Conv2d 147456 True BatchNorm2d 256 True ____________________________________________________________________________ [] AvgPool2d ____________________________________________________________________________ 128 x 128 x 4 x 4 Conv2d 8192 True BatchNorm2d 256 True ReLU Conv2d 147456 True BatchNorm2d 256 True ReLU Conv2d 147456 True BatchNorm2d 256 True Sequential ReLU ____________________________________________________________________________ 128 x 256 x 2 x 2 Conv2d 294912 True BatchNorm2d 512 True ReLU Conv2d 589824 True BatchNorm2d 512 True ____________________________________________________________________________ [] AvgPool2d ____________________________________________________________________________ 128 x 256 x 2 x 2 Conv2d 32768 True BatchNorm2d 512 True ReLU Conv2d 589824 True BatchNorm2d 512 True ReLU Conv2d 589824 True BatchNorm2d 512 True Sequential ReLU ____________________________________________________________________________ 128 x 512 x 1 x 1 Conv2d 1179648 True BatchNorm2d 1024 True ReLU Conv2d 2359296 True BatchNorm2d 1024 True ____________________________________________________________________________ [] AvgPool2d ____________________________________________________________________________ 128 x 512 x 1 x 1 Conv2d 131072 True BatchNorm2d 1024 True ReLU Conv2d 2359296 True BatchNorm2d 1024 True ReLU Conv2d 2359296 True BatchNorm2d 1024 True Sequential ReLU AdaptiveAvgPool2d Flatten Dropout ____________________________________________________________________________ 128 x 1000 Linear 513000 True ____________________________________________________________________________ Total params: 11,708,168 Total trainable params: 11,708,168 Total non-trainable params: 0 Optimizer used: &lt;function Adam at 0x7f0e15897050&gt; Loss function: FlattenedLoss of CrossEntropyLoss() Model unfrozen Callbacks: - TrainEvalCallback - Recorder - ProgressCallback . cols = 8 rows = 4 fig = plt.figure(figsize=(cols, 1.2*rows)) for i in range(rows*cols): img = F.conv2d(um_seis.view(1,1,28,28), tensor(kernels[i:i+1]), stride=1, padding=1).view(28,28) fig.add_subplot(rows, cols, i + 1) plt.imshow(img, cmap=&#39;bwr&#39;) plt.title(f&#39;K{i+1}&#39;) plt.axis(&#39;off&#39;) plt.show() .",
            "url": "https://opassos.github.io/blog/2021/10/16/Como-uma-IA-encherga-o-Mundo.html",
            "relUrl": "/2021/10/16/Como-uma-IA-encherga-o-Mundo.html",
            "date": " • Oct 16, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Tutorial Gatos-vs-Cachorros-🙀x🐶",
            "content": ". from IPython.display import YouTubeVideo YouTubeVideo(&#39;-Sw87Dyh3Kss&#39;) . https://youtu.be/Sw87Dyh3Kss . Setup . !nvidia-smi . Fri Oct 15 16:26:50 2021 +--+ | NVIDIA-SMI 470.74 Driver Version: 460.32.03 CUDA Version: 11.2 | |-+-+-+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 Tesla V100-SXM2... Off | 00000000:00:04.0 Off | 0 | | N/A 35C P0 23W / 300W | 0MiB / 16160MiB | 0% Default | | | | N/A | +-+-+-+ +--+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | No running processes found | +--+ . !pip install -Uqqq fastai . from fastai.vision.all import * . Baixando o dataset . L(dir(URLs)) . (#95) [&#39;ADULT_SAMPLE&#39;,&#39;AG_NEWS&#39;,&#39;AMAZON_REVIEWS&#39;,&#39;AMAZON_REVIEWS_POLARITY&#39;,&#39;BIWI_HEAD_POSE&#39;,&#39;BIWI_SAMPLE&#39;,&#39;CALTECH_101&#39;,&#39;CAMVID&#39;,&#39;CAMVID_TINY&#39;,&#39;CARS&#39;...] . URLs.PETS . &#39;https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz&#39; . path = untar_data(URLs.PETS)/&#39;images&#39; path . Path(&#39;/root/.fastai/data/oxford-iiit-pet/images&#39;) . EDA (Explorando o Dataset) . files = get_image_files(path) . files . (#7390) [Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/British_Shorthair_204.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/boxer_165.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/basset_hound_125.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/Bombay_185.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/wheaten_terrier_92.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/yorkshire_terrier_47.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/Siamese_31.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/British_Shorthair_74.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/beagle_157.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/shiba_inu_176.jpg&#39;)...] . Image.open(path/&#39;pug_116.jpg&#39;) . Image.open(path/&#39;British_Shorthair_201.jpg&#39;) . Dataloader . def labeler(x): return &#39;Gato&#39; if x.name[0].isupper() else &#39;Cachorro&#39; . labeler(path/&#39;British_Shorthair_201.jpg&#39;) . &#39;Gato&#39; . labeler(path/&#39;pug_116.jpg&#39;) . &#39;Cachorro&#39; . files = get_image_files(path) files . (#7390) [Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/British_Shorthair_204.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/boxer_165.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/basset_hound_125.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/Bombay_185.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/wheaten_terrier_92.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/yorkshire_terrier_47.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/Siamese_31.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/British_Shorthair_74.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/beagle_157.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/shiba_inu_176.jpg&#39;)...] . labeler(files[0]) . &#39;Gato&#39; . dblock = DataBlock( blocks = [ImageBlock, CategoryBlock], # blocos que formata os dados splitter = RandomSplitter(valid_pct = 0.2, seed = 42), get_items = get_image_files, # função que carrega os dados get_y = labeler, # get_x = ... item_tfms = Resize(224), ) dls = dblock.dataloaders(path, num_workers = 2, bs = 64) dls.show_batch() . xb, yb = dls.one_batch() . Learner . learn = cnn_learner(dls, resnet50, metrics=accuracy) . /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /pytorch/c10/core/TensorImpl.h:1156.) return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode) . Transfer Learning . learn.fine_tune(3) . epoch train_loss valid_loss accuracy time . 0 | 0.090986 | 0.022098 | 0.993911 | 00:51 | . epoch train_loss valid_loss accuracy time . 0 | 0.075581 | 0.028851 | 0.991204 | 00:52 | . 1 | 0.034629 | 0.010006 | 0.995940 | 00:51 | . 2 | 0.016202 | 0.002749 | 0.999323 | 00:51 | . 0.999323 ** 12 . 0.9919061815543482 . Verifica&#231;&#227;o . learn.show_results() . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . (996+1+1+480) / 7390 . 0.2 . Testando com uma nova imagem . import ipywidgets as widgets uploader = widgets.FileUpload() uploader . img = PILImage.create(uploader.data[0]) label, _, probs = learn.predict(img) if label == &#39;Gato&#39;: print(f&#39;Isso é um {label} com {(probs[1].item()*100):.1f}% de certeza&#39;) else: print(f&#39;Isso é um {label} com {(probs[0].item()*100):.1f}% de certeza&#39;) img.to_thumb(300) . Isso é um Gato com 100.0% de certeza . Problemas a serem resolvidos . E se a foto for de um leão? | E se o cachorro for o Pluto? | E se tivermos gatos e cachorros na foto? | E se a foto for de uma cadeira? | . Data Augmentation . dblock = DataBlock( blocks = [ImageBlock, CategoryBlock], get_items = get_image_files, get_y = labeler, item_tfms = Resize(256), batch_tfms = aug_transforms(mult = 2, size = 224) ) dls = dblock.dataloaders(path, num_workers = 2) . dls.show_batch(unique = True) .",
            "url": "https://opassos.github.io/blog/2021/10/15/Gatos-vs-Cachorros.html",
            "relUrl": "/2021/10/15/Gatos-vs-Cachorros.html",
            "date": " • Oct 15, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Tutorial Yolov5",
            "content": "Entre no repositório github do yolov5: https://github.com/ultralytics/yolov5 . | Abra o notebook colab . | . Clique no ícone [ ] para rodar o código de setup | . Aceite o aviso de que o notebook não foi criado pela Google . | O ícone [ ] deve mudar para um símbolo de play . | E depois de ser executado ele se tornará um número [1] . | Na aba chamada ‘Inferència’ é onde você irá colocar o vídeo que você quer detectar objetos. Existem varias opções, mas a mais simples é usar diretamente um vídeo do YouTube. Para isso, substitua o texto `data/images/´ pelo link do video. ** No caso, eu escolhi o trailer do Homem-Aranha 3: https://www.youtube.com/watch?v=EZo8V4XgzPY **Remova também a segunda linha. . | Clique no botão de ‘Play’ e espere alguns minutos (depdendendo do tamanho do vídeo) . | Para baixar o video anotado, abra a arvore dos arquivos . | O arquivo se encontra em: yolov5/runs/detect/exp/video.mp4 . | Para baixar clique nos 3 pontos e depois em download . | Um circulo de progressão será mostrado ao lado do nome do arquivo, quando ele ficar totalmente laranja o download será iniciado. . | E é isso! .",
            "url": "https://opassos.github.io/blog/2021/09/22/Tutorial-YoloV5.html",
            "relUrl": "/2021/09/22/Tutorial-YoloV5.html",
            "date": " • Sep 22, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Olá Mundo",
            "content": "Miss&#227;o . Sou um apaixonado por Deep Learning e decidi juntar a minha experiência em sala de aula com essa paixão. Em minhas redes sociais vou te ensinar o caminho mais curto para se tornar um especialista em Machine Learning e se tornar um profissional desejado e mais bem pago. . Meus Links: . GitHub | Kaggle | LinkedIn | Instagram | YouTube | Facebook | .",
            "url": "https://opassos.github.io/blog/ol%C3%A1%20mundo/jupyter/2021/09/20/Ola-Mundo.html",
            "relUrl": "/ol%C3%A1%20mundo/jupyter/2021/09/20/Ola-Mundo.html",
            "date": " • Sep 20, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://opassos.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://opassos.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}